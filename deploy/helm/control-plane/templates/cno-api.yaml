apiVersion: v1
kind: ServiceAccount
metadata:
  name: cno-api
  namespace: {{ .Release.Namespace }}
---

kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: cno-api
subjects:
  - kind: ServiceAccount
    name: cno-api
    namespace: {{ .Release.Namespace }}
roleRef:
  kind: ClusterRole
  name: cluster-admin
  apiGroup: rbac.authorization.k8s.io

---
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    deployment.kubernetes.io/revision: "3"
    fluxcd.io/automated: 'true'
  labels:
    app: cno-api
  {{- range $key, $value := .Values.global.cnoAPI.labels }}
    {{ $key  }}: {{ $value  }}
  {{- end }}
  name: cno-api
  namespace: {{ .Release.Namespace }}
spec:
  progressDeadlineSeconds: 600
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app: cno-api
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  template:
    metadata:
      labels:
        app: cno-api
      {{- range $key, $value := .Values.global.cnoAPI.labels }}
        {{ $key  }}: {{ $value  }}
      {{- end }}
    spec:
      initContainers:
        - name: kafka-check
          image: {{ .Values.kafkaConfig.image.name }}:{{ .Values.kafkaConfig.image.version }}
          env:
            - name: KAFKA_BROKERS
              value: cno-kafka-cluster-kafka-bootstrap:9092
            - name: SERVER_URL
              value: {{ .Values.global.cnoAPI.protocol }}://api.{{ .Values.expose.ingress.domain }}
            - name: UI_URL
              value: {{ .Values.global.cnoAPI.protocol }}://{{ .Values.expose.ingress.domain }}
          command:
            - /bin/sh
            - -c
          args:
            - |
              while true; do
                 bin/kafka-console-producer.sh --bootstrap-server $KAFKA_BROKERS --topic cno-kafka-health-check &> /dev/null
                 if [[ $? == 0 ]]; then
                    echo Successed: `date`
                    break
                 fi
                 echo Kafka unvailable `date`
                 sleep 5
              done
      containers:
        - image: {{ .Values.global.cnoAPI.image.name }}:{{ .Values.global.cnoAPI.image.version }}
          imagePullPolicy: Always
          name: cno-api
          {{- if hasKey .Values.global.cnoAPI "resources" }}
          resources:
            {{- toYaml .Values.global.cnoAPI.resources | nindent 12 }}
          {{- end }}
          ports:
            - containerPort: 8080
              protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          env:
            - name: DEFAULT_SUPER_ADMIN_PASSWORD
              {{- if hasKey .Values.superadmin "secret" }}
              valueFrom:
                secretKeyRef:
                  name: {{ .Values.superadmin.secret.name | quote }}
                  key: {{ default "PASSWORD" .Values.superadmin.secret.key | quote }}
              {{- else }}
              value: {{ .Values.superadmin.password }}
              {{- end }}
            - name: IN_CLUSTER
              value: "true"
            - name: SERVER_PORT
              value: "8080"
            - name: KAFKA_BROKERS
              value: cno-kafka-cluster-kafka-bootstrap:9093
            - name: KAFKA_TlS_ENABLED
              value: "true"
            - name: KAFKA_TLS_SKIP_VERIFY
              value: "false"
            - name: KAFKA_VERBOSE
              value: "false"
            - name: CNO_NAMESPACE
              value:  {{ .Release.Namespace }}
            - name: KAFKA_CLUSTER_NAME
              value: cno-kafka-cluster
{{ include "cno-chart.databaseConfig" . | indent 12 }}
            - name: CREATE_DEFAULT_CLUSTER
              value: {{ .Values.agentConfig.defaultCluster | quote }}
            {{- if and (eq .Values.expose.type "nginx-ingress") }}
            - name: DEFAULT_EXTERNAL_BROKERS_URL
              value: endpoint-0.{{ .Values.expose.ingress.domain }}:443
            - name: SERVER_URL
              value: https://api.{{ .Values.expose.ingress.domain }}
            {{- end }}
            {{- if .Values.agentConfig.defaultCluster }}
            - name: DEFAULT_CLUSTER_ID
              value: {{ include "cno-chart.clusterAgentUuid" . }}
            - name: DEFAULT_CLUSTER_TYPE
              value: {{ .Values.agentConfig.defaultClusterType }}
            - name: DEFAULT_CLUSTER_API_SERVER_URL
              value: {{ .Values.cluster.apiUrl }}
            {{- end }}
            - name: KAFKA_CA_CERT
              value: /kafka/ca/ca.crt
            - name: KAFKA_CLIENT_CERT
              value: /kafka/user/user.crt
            - name: KAFKA_CLIENT_KEY
              value: /kafka/user/user.key
          volumeMounts:
            - name: kafka-user
              mountPath: /kafka/user
            - name: kafka-ca
              mountPath: /kafka/ca
        - name: cloud-sql-proxy
          # It is recommended to use the latest version of the Cloud SQL Auth Proxy
          # Make sure to update on a regular schedule!
          image: gcr.io/cloud-sql-connectors/cloud-sql-proxy:2.1.0
          args:
            # If connecting from a VPC-native GKE cluster, you can use the
            # following flag to have the proxy connect over private IP
            - "--private-ip"

            # Enable structured logging with LogEntry format:
            - "--structured-logs"

            # Replace DB_PORT with the port the proxy should listen on
            - "--port=3306"
            - "cno-saas-prod:europe-west1:cno-db-instance"
            - "--credentials-file=/secrets/service_account.json"
          volumeMounts:
            - name: cloudsql-sa
              mountPath: /secrets
          securityContext:
            # The default Cloud SQL Auth Proxy image runs as the
            # "nonroot" user and group (uid: 65532) by default.
            runAsNonRoot: true
          # You should use resource requests/limits as a best practice to prevent
          # pods from consuming too many resources and affecting the execution of
          # other pods. You should adjust the following values based on what your
          # application needs. For details, see
          # https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
          resources:
            requests:
              # The proxy's memory use scales linearly with the number of active
              # connections. Fewer open connections will use less memory. Adjust
              # this value based on your application's requirements.
              memory: "2Gi"
              # The proxy's CPU use scales linearly with the amount of IO between
              # the database and the application. Adjust this value based on your
              # application's requirements.
              cpu:    "1"
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      terminationGracePeriodSeconds: 30
      serviceAccountName: cno-api
      volumes:
        - name: kafka-user
          secret:
            secretName: cno-kafka-superadmin
        - name: kafka-ca
          secret:
            secretName: cno-kafka-cluster-cluster-ca-cert
        - name: cloudsql-sa
          secret:
            secretName: cloudsql-sa


---
apiVersion: v1
kind: Service
metadata:
  name: {{ .Values.global.cnoAPI.internalServiceName }}
  namespace: {{ .Release.Namespace }}
spec:
  ports:
    - protocol: TCP
      port: 80
      targetPort: 8080
  selector:
    app: cno-api
  sessionAffinity: None
  {{- if eq .Values.expose.type "loadbalancer" }}
  type: LoadBalancer
  {{- end }}
  {{- if eq .Values.expose.type "nodeport" }}
  type: NodePort
  {{- end }}
